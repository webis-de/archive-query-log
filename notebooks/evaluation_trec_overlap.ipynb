{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "environ['PYSPARK_PYTHON'] = \"/mnt/ceph/storage/data-in-progress/data-research/web-search/web-archive-query-log/venv/bin/python\"\n",
    "session = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"web-archive-query-log-trec-overlap\") \\\n",
    "    .config(\"spark.executor.instances\", 3) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.23.88.185:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>web-archive-query-log-trec-overlap</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=web-archive-query-log-trec-overlap>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = session.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/ceph/storage/data-in-progress/data-research/web-search/web-archive-query-log')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "global_data_dir = Path(\"/mnt/ceph/storage/data-in-progress/data-research/web-search/web-archive-query-log/\")\n",
    "global_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/ceph/storage/data-in-progress/data-research/web-search/web-archive-query-log/focused')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = global_data_dir / \"focused\"\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# TODO: For final evaluation, use the full corpus.\n",
    "# corpus_dir = Path(\"/mnt/ceph/storage/data-in-progress/data-research/web-search/web-archive-query-log/focused/corpus\")\n",
    "# queries_dir = corpus_dir / \"queries-2023-02-XX\"\n",
    "# documents_dir = corpus_dir / \"documents-2023-02-XX\"\n",
    "corpus_dir = Path(\"/mnt/ceph/storage/data-in-progress/data-research/web-search/web-archive-query-log/focused/sample-corpus\")\n",
    "queries_dir = corpus_dir / \"queries-2023-02-18\"\n",
    "documents_dir = corpus_dir / \"documents-2023-02-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "figures_dir = Path(\"figures\")\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_jsonl(service: str, base_type: str):\n",
    "    base_path = data_dir / base_type / service\n",
    "    if not base_path.exists():\n",
    "        return []\n",
    "    yield from base_path.glob(\"*/*.jsonl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_warc(service: str, base_type: str):\n",
    "    base_path = data_dir / base_type / service\n",
    "    if not base_path.exists():\n",
    "        return []\n",
    "    for path in base_path.glob(\"*/*\"):\n",
    "        if path.is_dir():\n",
    "            yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gzip import GzipFile\n",
    "\n",
    "\n",
    "def count_jsonl(path: Path) -> int:\n",
    "    print(f\"Count JSONL records in {path}.\")\n",
    "    try:\n",
    "        with GzipFile(path, \"r\") as file:\n",
    "            return sum(1 for _ in file)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads, JSONDecodeError\n",
    "from typing import Iterator\n",
    "\n",
    "def read_jsonl(path: Path) -> Iterator:\n",
    "    print(f\"Read JSONL records in {path}.\")\n",
    "    try:\n",
    "        with GzipFile(path, \"r\") as gzip_file:\n",
    "            for line in gzip_file:\n",
    "                try:\n",
    "                    url = loads(line)\n",
    "                except JSONDecodeError:\n",
    "                    continue\n",
    "                yield url\n",
    "    except:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Path(\"services.txt\").open(\"rt\") as file:\n",
    "    alexa_services = [\n",
    "        line.strip()\n",
    "        for line in file\n",
    "        if line\n",
    "    ]\n",
    "len(alexa_services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "\n",
    "# num_search_results_per_serp = sc.parallelize(alexa_services, 1000)\\\n",
    "#     .flatMap(lambda service: paths_jsonl(service, \"archived-parsed-serps\"))\\\n",
    "#     .flatMap(read_jsonl)\\\n",
    "#     .filter(lambda serp: serp[\"results\"] is not None)\\\n",
    "#     .map(lambda serp: len(serp[\"results\"]))\\\n",
    "#     .mean()\n",
    "# num_search_results_per_serp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "\n",
    "# num_interpreted_query = sc.parallelize(alexa_services, 1000)\\\n",
    "#     .flatMap(lambda service: paths_jsonl(service, \"archived-parsed-serps\"))\\\n",
    "#     .flatMap(read_jsonl)\\\n",
    "#     .filter(lambda serp: serp[\"interpreted_query\"] is not None)\\\n",
    "#     .count()\n",
    "# num_interpreted_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ir-datasets in /opt/conda/lib/python3.8/site-packages (0.5.4)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (1.23.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (6.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (4.9.2)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (0.2.3)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (0.1.9)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (2.28.1)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (0.1.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (4.11.1)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (3.2.0.post0)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (4.64.1)\n",
      "Requirement already satisfied: lz4>=3.1.1 in /opt/conda/lib/python3.8/site-packages (from ir-datasets) (4.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->ir-datasets) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->ir-datasets) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->ir-datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.22.0->ir-datasets) (3.4)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ir-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_tasks = {\n",
    "    \"Robust\": {\n",
    "        2004: \"disks45/nocr/trec-robust-2004\",\n",
    "        2005: \"aquaint/trec-robust-2005\",\n",
    "    },\n",
    "    \"Terabyte\": {\n",
    "        2004: \"gov2/trec-tb-2004\",\n",
    "        2005: \"gov2/trec-tb-2005\",\n",
    "        2006: \"gov2/trec-tb-2006\",\n",
    "    },\n",
    "    \"MQ\": {\n",
    "        2007: \"gov2/trec-mq-2007\",\n",
    "        2008: \"gov2/trec-mq-2008\",\n",
    "        2009: \"clueweb09/trec-mq-2009\",\n",
    "    },\n",
    "    \"Web\": {\n",
    "        2002: \"gov/trec-web-2002\",\n",
    "        2003: \"gov/trec-web-2003\",\n",
    "        2004: \"gov/trec-web-2004\",\n",
    "        2009: \"clueweb09/catb/trec-web-2009\",\n",
    "        2010: \"clueweb09/catb/trec-web-2010\",\n",
    "        2011: \"clueweb09/catb/trec-web-2011\",\n",
    "        2012: \"clueweb09/catb/trec-web-2012\",\n",
    "        2013: \"clueweb12/trec-web-2013\",\n",
    "        2014: \"clueweb12/trec-web-2014\",\n",
    "    },\n",
    "    \"Deep Learning\": {\n",
    "        2019: \"msmarco-document-v2/trec-dl-2019\",\n",
    "        2020: \"msmarco-document-v2/trec-dl-2020\",\n",
    "        2021: \"msmarco-document-v2/trec-dl-2021\",\n",
    "        2022: \"msmarco-passage-v2/trec-dl-2022\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_datasets import load\n",
    "\n",
    "def query_titles(irdsid: str) -> list:\n",
    "    return [\n",
    "        query.query.lower() if hasattr(query, \"query\") else \n",
    "        query.title.lower() if hasattr(query, \"title\") else \n",
    "        query.text.lower()\n",
    "        for query in load(irdsid).queries_iter()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_titles(trec_tasks[\"Web\"][2002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "irdsids = [\n",
    "    irdsid\n",
    "    for _, years in trec_tasks.items()\n",
    "    for _, irdsid in years.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_queries = {\n",
    "    irdsid: query_titles(irdsid)\n",
    "    for irdsid in irdsids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_unique_queries = {\n",
    "    irdsid: set(qs)\n",
    "    for irdsid, qs in irds_queries.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_all_unique_queries = {\n",
    "    q\n",
    "    for _, qs in irds_unique_queries.items()\n",
    "    for q in qs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_all_matched_queries = sc.parallelize(alexa_services, 1000)\\\n",
    "    .flatMap(lambda service: paths_jsonl(service, \"archived-query-urls\"))\\\n",
    "    .repartition(1000)\\\n",
    "    .flatMap(read_jsonl)\\\n",
    "    .map(lambda serp: serp[\"query\"].lower())\\\n",
    "    .filter(lambda q: q in irds_all_unique_queries)\\\n",
    "    .distinct()\\\n",
    "    .collect()\n",
    "irds_all_matched_queries = set(irds_all_matched_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_non_mathed_queries = {\n",
    "    irdsid: qs - irds_all_matched_queries\n",
    "    for irdsid, qs in irds_unique_queries.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "irds_overlap = {\n",
    "    irdsid: 1 - (len(nmqs) / len(irds_queries[irdsid]))\n",
    "    for irdsid, nmqs in irds_non_mathed_queries.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2012,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 2022]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_range = list(range(\n",
    "    min(min(years) for _, years in trec_tasks.items()),\n",
    "    max(max(years) for _, years in trec_tasks.items()) + 1,\n",
    "))\n",
    "year_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Robust': {2004: 0.32799999999999996, 2005: 0.54},\n",
       " 'Terabyte': {2004: 0.19999999999999996,\n",
       "  2005: 0.26,\n",
       "  2006: 0.33999999999999997},\n",
       " 'MQ': {2007: 0.07420000000000004, 2008: 0.0988, 2009: 0.00017500000000003624},\n",
       " 'Web': {2002: 0.16000000000000003,\n",
       "  2003: 0.72,\n",
       "  2004: 0.31999999999999995,\n",
       "  2009: 0.72,\n",
       "  2010: 0.74,\n",
       "  2011: 0.30000000000000004,\n",
       "  2012: 0.6799999999999999,\n",
       "  2013: 0.5800000000000001,\n",
       "  2014: 0.56},\n",
       " 'Deep Learning': {2019: 0.0050000000000000044,\n",
       "  2020: 0.0050000000000000044,\n",
       "  2021: 0.002096436058700246,\n",
       "  2022: 0.02400000000000002}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trec_overlaps = {\n",
    "    track: {\n",
    "        year: irds_overlap[irdsid]\n",
    "        for year, irdsid in years.items()\n",
    "    }\n",
    "    for track, years in trec_tasks.items()\n",
    "}\n",
    "trec_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{Track} & \\textbf{Robust} & \\textbf{Terabyte} & \\textbf{MQ} & \\textbf{Web} & \\textbf{Deep Learning} \\\\\n",
      "\\midrule\n",
      "2002 & -- & -- & -- & 16\\,\\% & -- \\\\\n",
      "2003 & -- & -- & -- & 72\\,\\% & -- \\\\\n",
      "2004 & 33\\,\\% & 20\\,\\% & -- & 32\\,\\% & -- \\\\\n",
      "2005 & 54\\,\\% & 26\\,\\% & -- & -- & -- \\\\\n",
      "2006 & -- & 34\\,\\% & -- & -- & -- \\\\\n",
      "2007 & -- & -- & 7\\,\\% & -- & -- \\\\\n",
      "2008 & -- & -- & 10\\,\\% & -- & -- \\\\\n",
      "2009 & -- & -- & 0\\,\\% & 72\\,\\% & -- \\\\\n",
      "2010 & -- & -- & -- & 74\\,\\% & -- \\\\\n",
      "2011 & -- & -- & -- & 30\\,\\% & -- \\\\\n",
      "2012 & -- & -- & -- & 68\\,\\% & -- \\\\\n",
      "2013 & -- & -- & -- & 58\\,\\% & -- \\\\\n",
      "2014 & -- & -- & -- & 56\\,\\% & -- \\\\\n",
      "2015 & -- & -- & -- & -- & -- \\\\\n",
      "2016 & -- & -- & -- & -- & -- \\\\\n",
      "2017 & -- & -- & -- & -- & -- \\\\\n",
      "2018 & -- & -- & -- & -- & -- \\\\\n",
      "2019 & -- & -- & -- & -- & 1\\,\\% \\\\\n",
      "2020 & -- & -- & -- & -- & 1\\,\\% \\\\\n",
      "2021 & -- & -- & -- & -- & 0\\,\\% \\\\\n",
      "2022 & -- & -- & -- & -- & 2\\,\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "line = [fr\"\\textbf{{{track}}}\"for track in trec_overlaps.keys()]\n",
    "print(fr\"\\textbf{{Track}} & {' & '.join(line)} \\\\\")\n",
    "print(r\"\\midrule\")\n",
    "for year in year_range:\n",
    "    line = [\n",
    "        fr\"{(year_overlaps[year] * 100):.0f}\\,\\%\" if year in year_overlaps else \"--\"\n",
    "        for track, year_overlaps in trec_overlaps.items()\n",
    "    ]\n",
    "    print(fr\"{year} & {' & '.join(line)} \\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
