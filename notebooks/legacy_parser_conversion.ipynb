{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, UTC\n",
    "from typing import Literal, Annotated, TypeAlias\n",
    "from uuid import UUID\n",
    "\n",
    "from annotated_types import Ge\n",
    "from elasticsearch_dsl import (\n",
    "    Date as _Date,\n",
    "    RankFeature as _RankFeature,\n",
    "    Keyword as _Keyword,\n",
    ")\n",
    "from pydantic import Field, AliasChoices\n",
    "\n",
    "from elasticsearch_pydantic import (\n",
    "    BaseDocument,\n",
    "    BaseInnerDocument,\n",
    "    KeywordField as Keyword,\n",
    ")\n",
    "\n",
    "\n",
    "IntKeyword: TypeAlias = Annotated[int, _Keyword]\n",
    "Date: TypeAlias = Annotated[\n",
    "    datetime,\n",
    "    _Date(\n",
    "        default_timezone=\"UTC\",\n",
    "        format=\"strict_date_time_no_millis\",\n",
    "    ),\n",
    "]\n",
    "DefaultDate: TypeAlias = Annotated[\n",
    "    Date,\n",
    "    Field(default_factory=lambda: datetime.now(UTC)),\n",
    "]\n",
    "FloatRankFeature: TypeAlias = Annotated[\n",
    "    float,\n",
    "    Ge(0),\n",
    "    _RankFeature(positive_score_impact=True),\n",
    "]\n",
    "IntRankFeature: TypeAlias = Annotated[\n",
    "    int,\n",
    "    Ge(0),\n",
    "    _RankFeature(positive_score_impact=True),\n",
    "]\n",
    "\n",
    "\n",
    "class UuidBaseDocument(BaseDocument):\n",
    "    id: UUID = Field(  # type: ignore[override]\n",
    "        default_factory=UUID,\n",
    "        validation_alias=AliasChoices(\"_id\", \"id\"),\n",
    "        serialization_alias=\"_id\",\n",
    "    )\n",
    "\n",
    "\n",
    "class InnerProviderId(BaseInnerDocument):\n",
    "    id: UUID\n",
    "\n",
    "\n",
    "UrlQueryParserType = Literal[\n",
    "    \"query_parameter\",\n",
    "    \"fragment_parameter\",\n",
    "    \"path_segment\",\n",
    "]\n",
    "\n",
    "\n",
    "class UrlQueryParser(UuidBaseDocument):\n",
    "    last_modified: DefaultDate\n",
    "    provider: InnerProviderId | None = None\n",
    "    url_pattern_regex: Keyword | None = None\n",
    "    priority: FloatRankFeature | None = None\n",
    "    parser_type: UrlQueryParserType\n",
    "    parameter: Keyword | None = None\n",
    "    segment: IntKeyword | None = None\n",
    "    remove_pattern_regex: Keyword | None = None\n",
    "    space_pattern_regex: Keyword | None = None\n",
    "\n",
    "    class Index:\n",
    "        name = \"aql_url_query_parsers\"\n",
    "        settings = {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 2,\n",
    "        }\n",
    "\n",
    "\n",
    "UrlPageParserType = Literal[\n",
    "    \"query_parameter\",\n",
    "    \"fragment_parameter\",\n",
    "    \"path_segment\",\n",
    "]\n",
    "\n",
    "\n",
    "class UrlPageParser(UuidBaseDocument):\n",
    "    last_modified: DefaultDate\n",
    "    provider: InnerProviderId | None = None\n",
    "    url_pattern_regex: Keyword | None = None\n",
    "    priority: FloatRankFeature | None = None\n",
    "    parser_type: UrlPageParserType\n",
    "    parameter: Keyword | None = None\n",
    "    segment: IntKeyword | None = None\n",
    "    remove_pattern_regex: Keyword | None = None\n",
    "    space_pattern_regex: Keyword | None = None\n",
    "\n",
    "    class Index:\n",
    "        name = \"aql_url_page_parsers\"\n",
    "        settings = {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 2,\n",
    "        }\n",
    "\n",
    "\n",
    "UrlOffsetParserType = Literal[\n",
    "    \"query_parameter\",\n",
    "    \"fragment_parameter\",\n",
    "    \"path_segment\",\n",
    "]\n",
    "\n",
    "\n",
    "class UrlOffsetParser(UuidBaseDocument):\n",
    "    last_modified: DefaultDate\n",
    "    provider: InnerProviderId | None = None\n",
    "    url_pattern_regex: Keyword | None = None\n",
    "    priority: FloatRankFeature | None = None\n",
    "    parser_type: UrlOffsetParserType\n",
    "    parameter: Keyword | None = None\n",
    "    segment: IntKeyword | None = None\n",
    "    remove_pattern_regex: Keyword | None = None\n",
    "    space_pattern_regex: Keyword | None = None\n",
    "\n",
    "    class Index:\n",
    "        name = \"aql_url_offset_parsers\"\n",
    "        settings = {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 2,\n",
    "        }\n",
    "\n",
    "\n",
    "WarcQueryParserType = Literal[\"xpath\"]\n",
    "\n",
    "\n",
    "class WarcQueryParser(UuidBaseDocument):\n",
    "    last_modified: DefaultDate\n",
    "    provider: InnerProviderId | None = None\n",
    "    url_pattern_regex: Keyword | None = None\n",
    "    priority: FloatRankFeature | None = None\n",
    "    parser_type: WarcQueryParserType\n",
    "    xpath: Keyword | None = None\n",
    "    remove_pattern_regex: Keyword | None = None\n",
    "    space_pattern_regex: Keyword | None = None\n",
    "\n",
    "    class Index:\n",
    "        name = \"aql_warc_query_parsers\"\n",
    "        settings = {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 2,\n",
    "        }\n",
    "\n",
    "\n",
    "WarcWebSearchResultBlocksParserType = Literal[\"xpath\"]\n",
    "\n",
    "\n",
    "class WarcWebSearchResultBlocksParser(UuidBaseDocument):\n",
    "    last_modified: DefaultDate\n",
    "    provider: InnerProviderId | None = None\n",
    "    url_pattern_regex: Keyword | None = None\n",
    "    priority: FloatRankFeature | None = None\n",
    "    parser_type: WarcWebSearchResultBlocksParserType\n",
    "    xpath: Keyword | None = None\n",
    "    url_xpath: Keyword | None = None\n",
    "    title_xpath: Keyword | None = None\n",
    "    text_xpath: Keyword | None = None\n",
    "\n",
    "    class Index:\n",
    "        name = \"aql_warc_snippets_parsers\"\n",
    "        settings = {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 2,\n",
    "        }\n",
    "\n",
    "\n",
    "WarcSpecialContentsResultBlocksParserType = Literal[\"xpath\"]\n",
    "\n",
    "\n",
    "class WarcSpecialContentsResultBlocksParser(UuidBaseDocument):\n",
    "    last_modified: DefaultDate\n",
    "    provider: InnerProviderId | None = None\n",
    "    url_pattern_regex: Keyword | None = None\n",
    "    priority: FloatRankFeature | None = None\n",
    "    parser_type: WarcSpecialContentsResultBlocksParserType\n",
    "    xpath: Keyword | None = None\n",
    "    url_xpath: Keyword | None = None\n",
    "    text_xpath: Keyword | None = None\n",
    "\n",
    "    class Index:\n",
    "        name = \"aql_warc_direct_answers_parsers\"\n",
    "        settings = {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 2,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from elasticsearch_dsl.connections import create_connection\n",
    "\n",
    "load_dotenv(override=True)\n",
    "create_connection( \n",
    "            hosts=\"https://elasticsearch.srv.webis.de:9200\",\n",
    "            http_auth=(\"ajjxp\", \"jE7CjHPhXA3zAHgPxnzypsjLpfrjfET7\"),\n",
    "            timeout=60,\n",
    "            max_retries=5,\n",
    "            retry_on_status=(502, 503, 504),\n",
    "            retry_on_timeout=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archive_query_log.orm import Provider\n",
    "\n",
    "\n",
    "providers: list[Provider] = list(Provider.search(index=\"aql_providers\").scan())\n",
    "provider_names = {p.id: p.name for p in providers}\n",
    "provider_priorities = {p.id: p.priority for p in providers if p.priority is not None}\n",
    "provider_domains = {p.id: p.domains[0] for p in providers if p.domains is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78542930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "url_query_parsers: list[UrlQueryParser] = list(UrlQueryParser.search().scan())\n",
    "url_query_parsers.sort(\n",
    "    key=lambda parser: (\n",
    "        provider_priorities.get(parser.provider.id, -1)\n",
    "        if parser.provider is not None\n",
    "        else None,\n",
    "        parser.provider.id if parser.provider is not None else None,\n",
    "        parser.priority or None,\n",
    "        parser.id,\n",
    "    ),\n",
    "    reverse=True,\n",
    ")\n",
    "for provider_id, group in groupby(\n",
    "    url_query_parsers, key=lambda p: p.provider.id if p.provider is not None else None\n",
    "):\n",
    "    print(\n",
    "        f\"# Provider: {provider_names.get(provider_id, 'Global') if provider_id is not None else 'Global'}\"\n",
    "        + f\" ({provider_domains[provider_id]})\"\n",
    "        if provider_id is not None\n",
    "        else \"\"\n",
    "    )\n",
    "    for url_query_parser in group:\n",
    "        parameters = []\n",
    "        if url_query_parser.provider is not None:\n",
    "            parameters.append(f'provider_id=UUID(\"{url_query_parser.provider.id}\")')\n",
    "        if url_query_parser.url_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'url_pattern=re_compile(r\"{url_query_parser.url_pattern_regex}\")'\n",
    "            )\n",
    "        parser_class: str\n",
    "        if url_query_parser.parser_type == \"query_parameter\":\n",
    "            parser_class = \"QueryParameterUrlQueryParser\"\n",
    "            if url_query_parser.parameter is None:\n",
    "                raise ValueError(\"Missing parameter for parser.\")\n",
    "            parameters.append(f'parameter=\"{url_query_parser.parameter}\"')\n",
    "        elif url_query_parser.parser_type == \"fragment_parameter\":\n",
    "            parser_class = \"FragmentParameterUrlQueryParser\"\n",
    "            if url_query_parser.parameter is None:\n",
    "                raise ValueError(\"Missing parameter for parser.\")\n",
    "            parameters.append(f'parameter=\"{url_query_parser.parameter}\"')\n",
    "        elif url_query_parser.parser_type == \"path_segment\":\n",
    "            parser_class = \"PathSegmentUrlQueryParser\"\n",
    "            if url_query_parser.segment is None:\n",
    "                raise ValueError(\"Missing segment for parser.\")\n",
    "            parameters.append(f\"segment={url_query_parser.segment}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown parser type: {url_query_parser.parser_type}\")\n",
    "        if url_query_parser.remove_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'remove_pattern=re_compile(r\"{url_query_parser.remove_pattern_regex}\")'\n",
    "            )\n",
    "        if url_query_parser.space_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'space_pattern=re_compile(r\"{url_query_parser.space_pattern_regex}\")'\n",
    "            )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "{parser_class}(\n",
    "    {\",\\n    \".join(parameters)},\n",
    "),\n",
    "    \"\"\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4211f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "url_page_parsers: list[UrlPageParser] = list(UrlPageParser.search().scan())\n",
    "url_page_parsers.sort(\n",
    "    key=lambda parser: (\n",
    "        provider_priorities.get(parser.provider.id, -1)\n",
    "        if parser.provider is not None\n",
    "        else None,\n",
    "        parser.provider.id if parser.provider is not None else None,\n",
    "        parser.priority or None,\n",
    "        parser.id,\n",
    "    ),\n",
    "    reverse=True,\n",
    ")\n",
    "for provider_id, group in groupby(\n",
    "    url_page_parsers, key=lambda p: p.provider.id if p.provider is not None else None\n",
    "):\n",
    "    print(\n",
    "        f\"# Provider: {provider_names.get(provider_id, 'Global') if provider_id is not None else 'Global'}\"\n",
    "        + f\" ({provider_domains[provider_id]})\"\n",
    "        if provider_id is not None\n",
    "        else \"\"\n",
    "    )\n",
    "    for url_page_parser in group:\n",
    "        parameters = []\n",
    "        if url_page_parser.provider is not None:\n",
    "            parameters.append(f'provider_id=UUID(\"{url_page_parser.provider.id}\")')\n",
    "        if url_page_parser.url_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'url_pattern=re_compile(r\"{url_page_parser.url_pattern_regex}\")'\n",
    "            )\n",
    "        parser_class: str\n",
    "        if url_page_parser.parser_type == \"query_parameter\":\n",
    "            parser_class = \"QueryParameterUrlPageParser\"\n",
    "            if url_page_parser.parameter is None:\n",
    "                raise ValueError(\"Missing parameter for parser.\")\n",
    "            parameters.append(f'parameter=\"{url_page_parser.parameter}\"')\n",
    "        elif url_page_parser.parser_type == \"fragment_parameter\":\n",
    "            parser_class = \"FragmentParameterUrlPageParser\"\n",
    "            if url_page_parser.parameter is None:\n",
    "                raise ValueError(\"Missing parameter for parser.\")\n",
    "            parameters.append(f'parameter=\"{url_page_parser.parameter}\"')\n",
    "        elif url_page_parser.parser_type == \"path_segment\":\n",
    "            parser_class = \"PathSegmentUrlPageParser\"\n",
    "            if url_page_parser.segment is None:\n",
    "                raise ValueError(\"Missing segment for parser.\")\n",
    "            parameters.append(f\"segment={url_page_parser.segment}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown parser type: {url_page_parser.parser_type}\")\n",
    "        if url_page_parser.remove_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'remove_pattern=re_compile(r\"{url_page_parser.remove_pattern_regex}\")'\n",
    "            )\n",
    "        if url_page_parser.space_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'space_pattern=re_compile(r\"{url_page_parser.space_pattern_regex}\")'\n",
    "            )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "{parser_class}(\n",
    "    {\",\\n    \".join(parameters)},\n",
    "),\n",
    "    \"\"\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "url_offset_parsers: list[UrlOffsetParser] = list(UrlOffsetParser.search().scan())\n",
    "url_offset_parsers.sort(\n",
    "    key=lambda parser: (\n",
    "        provider_priorities.get(parser.provider.id, -1)\n",
    "        if parser.provider is not None\n",
    "        else None,\n",
    "        parser.provider.id if parser.provider is not None else None,\n",
    "        parser.priority or None,\n",
    "        parser.id,\n",
    "    ),\n",
    "    reverse=True,\n",
    ")\n",
    "for provider_id, group in groupby(\n",
    "    url_offset_parsers, key=lambda p: p.provider.id if p.provider is not None else None\n",
    "):\n",
    "    print(\n",
    "        f\"# Provider: {provider_names.get(provider_id, 'Global') if provider_id is not None else 'Global'}\"\n",
    "        + f\" ({provider_domains[provider_id]})\"\n",
    "        if provider_id is not None\n",
    "        else \"\"\n",
    "    )\n",
    "    for url_offset_parser in group:\n",
    "        parameters = []\n",
    "        if url_offset_parser.provider is not None:\n",
    "            parameters.append(f'provider_id=UUID(\"{url_offset_parser.provider.id}\")')\n",
    "        if url_offset_parser.url_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'url_pattern=re_compile(r\"{url_offset_parser.url_pattern_regex}\")'\n",
    "            )\n",
    "        parser_class: str\n",
    "        if url_offset_parser.parser_type == \"query_parameter\":\n",
    "            parser_class = \"QueryParameterUrlOffsetParser\"\n",
    "            if url_offset_parser.parameter is None:\n",
    "                raise ValueError(\"Missing parameter for parser.\")\n",
    "            parameters.append(f'parameter=\"{url_offset_parser.parameter}\"')\n",
    "        elif url_offset_parser.parser_type == \"fragment_parameter\":\n",
    "            parser_class = \"FragmentParameterUrlOffsetParser\"\n",
    "            if url_offset_parser.parameter is None:\n",
    "                raise ValueError(\"Missing parameter for parser.\")\n",
    "            parameters.append(f'parameter=\"{url_offset_parser.parameter}\"')\n",
    "        elif url_offset_parser.parser_type == \"path_segment\":\n",
    "            parser_class = \"PathSegmentUrlOffsetParser\"\n",
    "            if url_offset_parser.segment is None:\n",
    "                raise ValueError(\"Missing segment for parser.\")\n",
    "            parameters.append(f\"segment={url_offset_parser.segment}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown parser type: {url_offset_parser.parser_type}\")\n",
    "        if url_offset_parser.remove_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'remove_pattern=re_compile(r\"{url_offset_parser.remove_pattern_regex}\")'\n",
    "            )\n",
    "        if url_offset_parser.space_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'space_pattern=re_compile(r\"{url_offset_parser.space_pattern_regex}\")'\n",
    "            )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "{parser_class}(\n",
    "    {\",\\n    \".join(parameters)},\n",
    "),\n",
    "    \"\"\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "warc_query_parsers: list[WarcQueryParser] = list(WarcQueryParser.search().scan())\n",
    "warc_query_parsers.sort(\n",
    "    key=lambda parser: (\n",
    "        provider_priorities.get(parser.provider.id, -1)\n",
    "        if parser.provider is not None\n",
    "        else None,\n",
    "        parser.provider.id if parser.provider is not None else None,\n",
    "        parser.priority or None,\n",
    "        parser.id,\n",
    "    ),\n",
    "    reverse=True,\n",
    ")\n",
    "for provider_id, group in groupby(\n",
    "    warc_query_parsers, key=lambda p: p.provider.id if p.provider is not None else None\n",
    "):\n",
    "    print(\n",
    "        f\"# Provider: {provider_names.get(provider_id, 'Global') if provider_id is not None else 'Global'}\"\n",
    "        + f\" ({provider_domains[provider_id]})\"\n",
    "        if provider_id is not None\n",
    "        else \"\"\n",
    "    )\n",
    "    for warc_query_parser in group:\n",
    "        parameters = []\n",
    "        if warc_query_parser.provider is not None:\n",
    "            parameters.append(f'provider_id=UUID(\"{warc_query_parser.provider.id}\")')\n",
    "        if warc_query_parser.url_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'url_pattern=re_compile(r\"{warc_query_parser.url_pattern_regex}\")'\n",
    "            )\n",
    "        parser_class: str\n",
    "        if warc_query_parser.parser_type == \"xpath\":\n",
    "            parser_class = \"XpathWarcQueryParser\"\n",
    "            if warc_query_parser.xpath is None:\n",
    "                raise ValueError(\"Missing xpath for parser.\")\n",
    "            parameters.append(f'xpath=\"{warc_query_parser.xpath}\"')\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown parser type: {warc_query_parser.parser_type}\")\n",
    "        if warc_query_parser.remove_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'remove_pattern=re_compile(r\"{warc_query_parser.remove_pattern_regex}\")'\n",
    "            )\n",
    "        if warc_query_parser.space_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'space_pattern=re_compile(r\"{warc_query_parser.space_pattern_regex}\")'\n",
    "            )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "{parser_class}(\n",
    "    {\",\\n    \".join(parameters)},\n",
    "),\n",
    "    \"\"\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "warc_web_search_result_blocks_parsers: list[WarcWebSearchResultBlocksParser] = list(\n",
    "    WarcWebSearchResultBlocksParser.search().scan()\n",
    ")\n",
    "warc_web_search_result_blocks_parsers.sort(\n",
    "    key=lambda parser: (\n",
    "        provider_priorities.get(parser.provider.id, -1)\n",
    "        if parser.provider is not None\n",
    "        else None,\n",
    "        parser.provider.id if parser.provider is not None else None,\n",
    "        parser.priority or None,\n",
    "        parser.id,\n",
    "    ),\n",
    "    reverse=True,\n",
    ")\n",
    "for provider_id, group in groupby(\n",
    "    warc_web_search_result_blocks_parsers,\n",
    "    key=lambda p: p.provider.id if p.provider is not None else None,\n",
    "):\n",
    "    print(\n",
    "        f\"# Provider: {provider_names.get(provider_id, 'Global') if provider_id is not None else 'Global'}\"\n",
    "        + f\" ({provider_domains[provider_id]})\"\n",
    "        if provider_id is not None\n",
    "        else \"\"\n",
    "    )\n",
    "    for warc_web_search_result_blocks_parser in group:\n",
    "        parameters = []\n",
    "        if warc_web_search_result_blocks_parser.provider is not None:\n",
    "            parameters.append(\n",
    "                f'provider_id=UUID(\"{warc_web_search_result_blocks_parser.provider.id}\")'\n",
    "            )\n",
    "        if warc_web_search_result_blocks_parser.url_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'url_pattern=re_compile(r\"{warc_web_search_result_blocks_parser.url_pattern_regex}\")'\n",
    "            )\n",
    "        parser_class: str\n",
    "        if warc_web_search_result_blocks_parser.parser_type == \"xpath\":\n",
    "            parser_class = \"XpathWarcWebSearchResultBlocksParser\"\n",
    "            if warc_web_search_result_blocks_parser.xpath is None:\n",
    "                raise ValueError(\"Missing xpath for parser.\")\n",
    "            parameters.append(f'xpath=\"{warc_web_search_result_blocks_parser.xpath}\"')\n",
    "            if warc_web_search_result_blocks_parser.url_xpath is not None:\n",
    "                parameters.append(\n",
    "                    f'url_xpath=\"{warc_web_search_result_blocks_parser.url_xpath}\"'\n",
    "                )\n",
    "            if warc_web_search_result_blocks_parser.title_xpath is not None:\n",
    "                parameters.append(\n",
    "                    f'title_xpath=\"{warc_web_search_result_blocks_parser.title_xpath}\"'\n",
    "                )\n",
    "            if warc_web_search_result_blocks_parser.text_xpath is not None:\n",
    "                parameters.append(\n",
    "                    f'text_xpath=\"{warc_web_search_result_blocks_parser.text_xpath}\"'\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown parser type: {warc_web_search_result_blocks_parser.parser_type}\"\n",
    "            )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "{parser_class}(\n",
    "    {\",\\n    \".join(parameters)},\n",
    "),\n",
    "    \"\"\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42131189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "warc_special_contents_result_blocks_parsers: list[WarcSpecialContentsResultBlocksParser] = list(\n",
    "    WarcSpecialContentsResultBlocksParser.search().scan()\n",
    ")\n",
    "warc_special_contents_result_blocks_parsers.sort(\n",
    "    key=lambda parser: (\n",
    "        provider_priorities.get(parser.provider.id, -1)\n",
    "        if parser.provider is not None\n",
    "        else None,\n",
    "        parser.provider.id if parser.provider is not None else None,\n",
    "        parser.priority or None,\n",
    "        parser.id,\n",
    "    ),\n",
    "    reverse=True,\n",
    ")\n",
    "for provider_id, group in groupby(\n",
    "    warc_special_contents_result_blocks_parsers,\n",
    "    key=lambda p: p.provider.id if p.provider is not None else None,\n",
    "):\n",
    "    print(\n",
    "        f\"# Provider: {provider_names.get(provider_id, 'Global') if provider_id is not None else 'Global'}\"\n",
    "        + f\" ({provider_domains[provider_id]})\"\n",
    "        if provider_id is not None\n",
    "        else \"\"\n",
    "    )\n",
    "    for warc_special_contents_result_blocks_parser in group:\n",
    "        parameters = []\n",
    "        if warc_special_contents_result_blocks_parser.provider is not None:\n",
    "            parameters.append(\n",
    "                f'provider_id=UUID(\"{warc_special_contents_result_blocks_parser.provider.id}\")'\n",
    "            )\n",
    "        if warc_special_contents_result_blocks_parser.url_pattern_regex is not None:\n",
    "            parameters.append(\n",
    "                f'url_pattern=re_compile(r\"{warc_special_contents_result_blocks_parser.url_pattern_regex}\")'\n",
    "            )\n",
    "        parser_class: str\n",
    "        if warc_special_contents_result_blocks_parser.parser_type == \"xpath\":\n",
    "            parser_class = \"XpathWarcSpecialContentsResultBlocksParser\"\n",
    "            if warc_special_contents_result_blocks_parser.xpath is None:\n",
    "                raise ValueError(\"Missing xpath for parser.\")\n",
    "            parameters.append(f'xpath=\"{warc_special_contents_result_blocks_parser.xpath}\"')\n",
    "            if warc_special_contents_result_blocks_parser.url_xpath is not None:\n",
    "                parameters.append(\n",
    "                    f'url_xpath=\"{warc_special_contents_result_blocks_parser.url_xpath}\"'\n",
    "                )\n",
    "            if warc_special_contents_result_blocks_parser.text_xpath is not None:\n",
    "                parameters.append(\n",
    "                    f'text_xpath=\"{warc_special_contents_result_blocks_parser.text_xpath}\"'\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown parser type: {warc_special_contents_result_blocks_parser.parser_type}\"\n",
    "            )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "{parser_class}(\n",
    "    {\",\\n    \".join(parameters)},\n",
    "),\n",
    "    \"\"\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87977a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
